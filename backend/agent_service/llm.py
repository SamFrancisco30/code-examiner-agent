import os
import configparser
from openai import AzureOpenAI
from tenacity import retry, stop_after_attempt, wait_exponential
from backend.tool.make_config import make_config
import json


def init_node(state: dict):
    """åˆå§‹åŒ–å¿…è¦å­—æ®µ"""
    return {
        "user_id": state.get("user_id", "test_user"),
        "question_id": state.get("question_id", ""),
        "event_type": state.get("event_type", "unknown"),
        "code_diff": state.get("code_diff", []),
        "question_name": state.get("question_name", ""),
        "question_desc": state.get("question_desc", ""),
        "example_input": state.get("example_input", ""),
        "example_output": state.get("example_output", ""),
        "elapsed_time": state.get("elapsed_time", 0),
        "tech_history": state.get("tech_history", []),
    }


def tech_analysis_node(state):
    tech_prompt = f"""
    ä½ æ˜¯ä¸€åé«˜çº§å¼€å‘å·¥ç¨‹å¸ˆï¼Œæ“…é•¿æ¦‚æ‹¬æŠ€æœ¯å†…å®¹ï¼Œä½ å…·å¤‡ç”¨ç²¾ç‚¼çš„è¯è¯­æè¿°ä»£ç æ¼”è¿›æƒ…å†µä¸ŽæŠ€æœ¯åˆ†æžçš„èƒ½åŠ›ã€‚
    æ³¨æ„äº‹é¡¹ï¼šåŒ…å«å…·ä½“çš„æŠ€æœ¯è¯´æ˜Žå’Œä»£ç æ¼”è¿›æƒ…å†µï¼Œè¯­è¨€è¦ç²¾ç‚¼å‡†ç¡®ï¼Œå¹¶æ³¨æ„åˆ†ç‚¹è¡¨ç¤ºã€‚
    ä½ çš„è¾“å‡ºåº”å½“ä½¿ç”¨jsonæ ¼å¼ï¼Œå…·ä½“å¦‚ä¸‹ï¼š
    {{
        "tech_analysis": [str],
    }}

    çŽ°åœ¨è¯·åˆ†æžå¦‚ä¸‹ä»£ç æ¼”è¿›ï¼š

    [é¢˜ç›®]
    {state.get('question_name', '')}

    [é¢˜ç›®è¦æ±‚]
    {state.get('question_desc', '')}

    [ç¤ºä¾‹è¾“å…¥]
    {state.get('example_input', '')}

    [ç¤ºä¾‹è¾“å‡º]
    {state.get('example_output', '')}

    [æ—¶é—´æ¶ˆè€—]
    {state.get('elapsed_time', 0)}ms

    [ä»£ç æ¼”è¿›æƒ…å†µ]
    {state.get('code_diff', [])}

    """

    response = azure_llm(
        tech_prompt,
        system_msg="ä½ æ“…é•¿è¯†åˆ«ä»£ç æ”¹è¿›å’ŒæŠ€æœ¯å€ºåŠ¡",
        temp=0.2
    )

    print("tech_analysis_node response: ", response)

    try:
        state["tech_analysis"] = json.loads(response)["tech_analysis"] if response else []
        return state
    except json.JSONDecodeError:
        state["tech_analysis"] = ['error']
        return state


def teaching_feedback_node(state: dict):
    feedback_prompt = f"""
    ä½ æ˜¯ä¸€åé«˜çº§å¼€å‘å·¥ç¨‹å¸ˆå…¼è®¡ç®—æœºæ•™å­¦å­¦è€…ï¼Œæ“…é•¿å°†æŠ€æœ¯åˆ†æžè½¬åŒ–ä¸ºæ•™å­¦æŒ‡å¯¼ã€‚
    ä½ å°†æ ¹æ®æŠ€æœ¯åˆ†æžç»“æžœç”Ÿæˆæ•™å­¦åé¦ˆï¼Œåé¦ˆåº”å½“å›Šæ‹¬å¦‚ä¸‹å†…å®¹ï¼š

    1. ç”¨æˆ·ç¼–ç¨‹è–„å¼±çŽ¯èŠ‚å»ºè®®ï¼ˆç”¨æˆ·åœ¨è¿›è¡ŒæŸäº›æ”¹åŠ¨æ—¶èŠ±è´¹æ—¶é—´å¾ˆå¤šï¼‰
    2. ç®—æ³•ä¼˜åŒ–ï¼ˆæ—¶é—´/ç©ºé—´å¤æ‚åº¦å˜åŒ–ï¼‰
    3. å¯ç»´æŠ¤æ€§ï¼ˆä»£ç å¯è¯»æ€§ã€æ–‡æ¡£å®Œå–„åº¦ï¼‰
    4. æ½œåœ¨é£Žé™©ï¼ˆé”™è¯¯å¤„ç†ã€è¾¹ç•Œæ¡ä»¶ï¼‰
    5. æž¶æž„æ”¹è¿›ï¼ˆæ¨¡å—åŒ–ã€è®¾è®¡æ¨¡å¼åº”ç”¨ï¼‰

    [è¦æ±‚]
    - ä½¿ç”¨äº²åˆ‡çš„ä¸­æ–‡å£å»
    - åŒ…å«å…·ä½“ä»£ç ç¤ºä¾‹è¯´æ˜Ž

    [è¾“å‡ºJSONæ ¼å¼]
    {{
        "progress": [str],
        "suggestions": [str],
        "summary": str
    }}

    [é¢˜ç›®]
    {state.get('question_name', '')}

    [é¢˜ç›®è¦æ±‚]
    {state.get('question_desc', '')}

    [ç¤ºä¾‹è¾“å…¥]
    {state.get('example_input', '')}

    [ç¤ºä¾‹è¾“å‡º]
    {state.get('example_output', '')}

    [æŠ€æœ¯åˆ†æžç»“æžœ]
    {state.get('tech_history', [])}
    """

    response = azure_llm(
        feedback_prompt,
        system_msg="ä½ æ“…é•¿å°†æŠ€æœ¯åˆ†æžè½¬åŒ–ä¸ºæ•™å­¦æŒ‡å¯¼",
        temp=0.5
    )

    try:
        feedback_data = json.loads(response) if response else {}
        return {"feedback": format_feedback(feedback_data)}
    except:
        return {"feedback": "åé¦ˆç”Ÿæˆå¤±è´¥"}


def format_feedback(data: dict) -> str:
    progress = "\n".join([f"âœ… {item}" for item in data.get("progress", [])])
    suggestions = "\n".join([f"ðŸ’¡ {item}" for item in data.get("suggestions", [])])
    summary = data.get("summary", "")

    print("feedback generated. progress:", progress)

    return f"""
ðŸŒŸ è¿›å±•äº®ç‚¹ï¼š
{progress}

ðŸš€ ä¼˜åŒ–å»ºè®®ï¼š
{suggestions}

ðŸ“ æ€»ç»“ï¼š
{summary}
"""

# è¯»å–é…ç½®æ–‡ä»¶
config = make_config()


# ä»Žé…ç½®æ–‡ä»¶ä¸­èŽ·å– Azure é…ç½®
azure_config = config.get('azure')
endpoint = azure_config.get('endpoint')
model_name = azure_config.get('model_name')
deployment = azure_config.get('deployment')
subscription_key = azure_config.get('subscription_key')
api_version = azure_config.get('api_version')

client = AzureOpenAI(
    api_version=api_version,
    azure_endpoint=endpoint,
    api_key=subscription_key,
)

# å®šä¹‰ Azure LLM å‡½æ•°
@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
def azure_llm(prompt: str, system_msg: str = None, temp=0.3) -> str:
    messages = []
    if system_msg:
        messages.append({"role": "system", "content": system_msg})
    messages.append({"role": "user", "content": prompt})

    try:
        response = client.chat.completions.create(
            model=deployment,
            messages=messages,
            temperature=temp,
            response_format={"type": "json_object"},
            max_tokens=1000
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"APIé”™è¯¯: {str(e)}")
        return None