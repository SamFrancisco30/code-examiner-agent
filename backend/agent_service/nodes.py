import json
from llm_utils import azure_llm

def init_node(state: dict):
    """åˆå§‹åŒ–å¿…è¦å­—æ®µ"""
    return {
        "user_id": state.get("user_id", "test_user"),
        "question_id": state.get("question_id", ""),
        "event_type": state.get("event_type", "unknown"),
        "code_diff": state.get("code_diff", []),
        "question_name": state.get("question_name", ""),
        "question_desc": state.get("question_desc", ""),
        "example_input": state.get("example_input", ""),
        "example_output": state.get("example_output", ""),
        "elapsed_time": state.get("elapsed_time", 0)
    }

def tech_analysis_node(state: dict):
    tech_prompt = f"""
    ä½ æ˜¯ä¸€åé«˜çº§å¼€å‘å·¥ç¨‹å¸ˆï¼Œæ“…é•¿æ¦‚æ‹¬æŠ€æœ¯å†…å®¹ï¼Œä½ å…·å¤‡ç”¨ç²¾ç‚¼çš„è¯è¯­æè¿°ä»£ç æ¼”è¿›æƒ…å†µä¸æŠ€æœ¯åˆ†æçš„èƒ½åŠ›ã€‚
    æ³¨æ„äº‹é¡¹ï¼šåŒ…å«å…·ä½“çš„æŠ€æœ¯è¯´æ˜å’Œä»£ç æ¼”è¿›æƒ…å†µï¼Œè¯­è¨€è¦ç²¾ç‚¼å‡†ç¡®ï¼Œå¹¶æ³¨æ„åˆ†ç‚¹è¡¨ç¤ºã€‚
    ä½ çš„è¾“å‡ºåº”å½“ä½¿ç”¨jsonæ ¼å¼ï¼Œå…·ä½“å¦‚ä¸‹ï¼š
    {{
        "tech_analysis": [str],
    }}
    
    ç°åœ¨è¯·åˆ†æå¦‚ä¸‹ä»£ç æ¼”è¿›ï¼š
    
    [é¢˜ç›®]
    {state.get('question_name', '')}

    [é¢˜ç›®è¦æ±‚]
    {state.get('question_desc', '')}

    [ç¤ºä¾‹è¾“å…¥]
    {state.get('example_input', '')}
    
    [ç¤ºä¾‹è¾“å‡º]
    {state.get('example_output', '')}

    [æ—¶é—´æ¶ˆè€—]
    {state.get('elapsed_time', 0)}ms
    
    [ä»£ç æ¼”è¿›æƒ…å†µ]
    {state.get('code_diff', [])}
    
    """

    response = azure_llm(
        tech_prompt,
        system_msg="ä½ æ“…é•¿è¯†åˆ«ä»£ç æ”¹è¿›å’ŒæŠ€æœ¯å€ºåŠ¡",
        temp=0.2
    )

    print("tech_analysis_node response: ", response)
    
    try:
        return {"llm_tech_analysis": json.loads(response) if response else {}}
    except json.JSONDecodeError:
        return {"llm_tech_analysis": {"error": "åˆ†æç»“æœè§£æå¤±è´¥"}}



def teaching_feedback_node(state: dict):
    if not state.get("llm_tech_analysis", ''):
        return {"feedback": "åˆ†ææ•°æ®ä¸è¶³"}
    
    feedback_prompt = f"""
    æ ¹æ®æŠ€æœ¯åˆ†æç»“æœç”Ÿæˆæ•™å­¦åé¦ˆï¼š
    {json.dumps(state.get("llm_tech_analysis", {}), indent=2)}
    
    è¦æ±‚ï¼š
    - ä½¿ç”¨äº²åˆ‡çš„ä¸­æ–‡å£å»
    - åŒ…å«å…·ä½“ä»£ç ç¤ºä¾‹è¯´æ˜
    - æ­£é¢åé¦ˆå’Œæ”¹è¿›å»ºè®®å„3æ¡
    - ä½¿ç”¨emojiå¢åŠ å¯è¯»æ€§
    
    è¾“å‡ºæ ¼å¼ï¼š
    {{
        "progress": [str],
        "suggestions": [str],
        "summary": str
    }}
    """
    
    response = azure_llm(
        feedback_prompt,
        system_msg="ä½ æ“…é•¿å°†æŠ€æœ¯åˆ†æè½¬åŒ–ä¸ºæ•™å­¦æŒ‡å¯¼",
        temp=0.5
    )
    
    try:
        feedback_data = json.loads(response) if response else {}
        return {"feedback": format_feedback(feedback_data)}
    except:
        return {"feedback": "åé¦ˆç”Ÿæˆå¤±è´¥"}



def format_feedback(data: dict) -> str:
    progress = "\n".join([f"âœ… {item}" for item in data.get("progress", [])])
    suggestions = "\n".join([f"ğŸ’¡ {item}" for item in data.get("suggestions", [])])
    summary = data.get("summary", "")

    print("feedback generated. progress:", progress)
    
    return f"""
ğŸŒŸ è¿›å±•äº®ç‚¹ï¼š
{progress}

ğŸš€ ä¼˜åŒ–å»ºè®®ï¼š
{suggestions}

ğŸ“ æ€»ç»“ï¼š
{summary}
"""